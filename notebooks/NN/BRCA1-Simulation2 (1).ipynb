{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 16385)\n",
      "new_train.shape =  (4000, 16385)\n",
      "(4000, 16385)\n",
      "new_test.shape =  (4000, 16385)\n"
     ]
    }
   ],
   "source": [
    "# NO NEED TO LOAD / READIN\n",
    "\n",
    "# READ IN CSV (takes 30 seconds)\n",
    "new_train_values = np.loadtxt(\"train_vectors2.csv\",delimiter=\",\")\n",
    "print(new_train_values.shape)\n",
    "new_train = new_train_values.reshape((4000,16385))\n",
    "print('new_train.shape = ',new_train.shape)\n",
    "\n",
    "\n",
    "new_test_values = np.loadtxt(\"test_vectors2.csv\",delimiter=\",\")\n",
    "print(new_test_values.shape)\n",
    "new_test = new_test_values.reshape((4000,16385))\n",
    "print('new_test.shape = ',new_test.shape)\n",
    "\n",
    "train_x = new_train[:,0:16384] \n",
    "train_y = new_train[:,16384]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "#===================\n",
    "test_x = new_test[:,0:16384] \n",
    "test_y = new_test[:,16384]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "# Compute Binary Cross-Entropy using NumPy\n",
    "def binary_cross_entropy_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Binary Cross-Entropy loss for multiple samples using NumPy.\n",
    "    y_true: NumPy array of actual labels (0s and 1s)\n",
    "    y_pred: NumPy array of predicted probabilities (between 0 and 1)\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15  # Small value to prevent log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# Compute Binary Cross-Entropy using own calculaton for checking\n",
    "def binary_cross_entropy_check(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Binary Cross-Entropy loss for multiple samples using NumPy.\n",
    "    y_true: NumPy array of actual labels (0s and 1s)\n",
    "    y_pred: NumPy array of predicted probabilities (between 0 and 1)\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15  # Small value to prevent log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "    \n",
    "    N=len(y_true)\n",
    "    BCE_sum=0\n",
    "    for i in range(N):\n",
    "        BCE_sum = BCE_sum + y_true[i]*np.log(y_pred[i]) + (1-y_true[i])*np.log((1-y_pred[i])) \n",
    "\n",
    "    BCE = (-1*BCE_sum)/N\n",
    "    \n",
    "    return BCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START RUNNING THE CODE BELOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 512)               10752     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 83,265\n",
      "Trainable params: 81,921\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# To define some ANN models\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_dim = 20))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid')) # Output layer for binary classification\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def baseline_model2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim = 20))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid')) # Output layer for binary classification\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the model\n",
    "# ANN_model = baseline_model()\n",
    "\n",
    "ANN_model = baseline_model()\n",
    "\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the balanced training and testing dataset\n",
    "# 40 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref vector  : ---   ---   ---   ---   ---   ---   ---   ---   ---   ---\n",
      "Var vector  : -C-   ---   ---   ---   ---   ---   ---   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   ---   ---   ---   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   ---   ---   -C-   ---   ---   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   ---   ---   ---   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   ---   ---   ---   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   -C-   ---   ---   ---   ---   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   ---   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   ---   ---   -C-   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   ---   ---   ---   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   ---   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   ---   ---   -C-   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   -C-   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   -C-   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : ---   ---   -C-   ---   ---   ---   -C-   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   ---   ---   -C-   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : -C-   ---   -C-   ---   -C-   ---   -C-   ---   ---   ---  label 1\n",
      "Var vector  : -C-   ---   -C-   ---   -C-   ---   ---   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   -C-   ---   ---   ---   -C-   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   ---   ---   -C-   ---   -C-   ---   -C-   ---  label 1\n",
      "Var vector  : -C-   ---   -C-   ---   -C-   ---   -C-   ---   -C-   ---  label 1\n",
      "================================================================================\n",
      "Var vector  : ---   -C-   ---   ---   ---   ---   ---   ---   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   ---   ---   ---   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   ---   ---   -C-   ---   ---   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   ---   ---   ---   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   ---   ---   ---   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   -C-   ---   ---   ---   ---   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   ---   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   ---   ---   -C-   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   ---   ---   ---   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   ---   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   ---   ---   -C-   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   -C-   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   -C-   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   ---   ---   -C-   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   ---   ---   -C-   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   -C-   ---   -C-   ---   -C-   ---   -C-   ---   ---  label 0\n",
      "Var vector  : ---   -C-   ---   -C-   ---   -C-   ---   ---   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   -C-   ---   ---   ---   -C-   ---   -C-  label 0\n",
      "Var vector  : ---   -C-   ---   ---   ---   -C-   ---   -C-   ---   -C-  label 0\n",
      "Var vector  : ---   ---   ---   -C-   ---   -C-   ---   -C-   ---   -C-  label 0\n"
     ]
    }
   ],
   "source": [
    "print('Ref vector  : ---   ---   ---   ---   ---   ---   ---   ---   ---   ---')\n",
    "print('Var vector  : -C-   ---   ---   ---   ---   ---   ---   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   ---   ---   ---   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   ---   ---   -C-   ---   ---   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   ---   ---   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   -C-   ---   ---   ---   ---   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   ---   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   ---   ---   -C-   ---   ---   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   ---   ---   ---   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   ---   ---   ---   ---   -C-   ---  label 1')\n",
    "\n",
    "print('Var vector  : -C-   ---   ---   ---   -C-   ---   ---   ---   -C-   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   -C-   ---   ---   ---   -C-   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   -C-   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : ---   ---   -C-   ---   ---   ---   -C-   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   ---   ---   -C-   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : -C-   ---   -C-   ---   -C-   ---   -C-   ---   ---   ---  label 1')\n",
    "print('Var vector  : -C-   ---   -C-   ---   -C-   ---   ---   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   -C-   ---   ---   ---   -C-   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   ---   ---   -C-   ---   -C-   ---   -C-   ---  label 1')\n",
    "print('Var vector  : -C-   ---   -C-   ---   -C-   ---   -C-   ---   -C-   ---  label 1')\n",
    "print('================================================================================')\n",
    "print('Var vector  : ---   -C-   ---   ---   ---   ---   ---   ---   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   ---   ---   ---   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   -C-   ---   ---   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   ---   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   ---   ---   ---   ---   -C-  label 0')\n",
    "print('Var vector  : ---   -C-   ---   -C-   ---   ---   ---   ---   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   ---   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   ---   ---   -C-   ---   ---   ---   -C-  label 0')\n",
    "print('Var vector  : ---   -C-   ---   ---   ---   ---   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   ---   ---   ---   ---   -C-  label 0')\n",
    "\n",
    "print('Var vector  : ---   -C-   ---   ---   ---   -C-   ---   ---   ---   -C-  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   -C-   ---   ---   ---   -C-  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   -C-   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   ---   ---   -C-   ---   -C-  label 0')\n",
    "print('Var vector  : ---   -C-   ---   ---   ---   -C-   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   -C-   ---   -C-   ---   -C-   ---   -C-   ---   ---  label 0')\n",
    "print('Var vector  : ---   -C-   ---   -C-   ---   -C-   ---   ---   ---   -C-  label 0')\n",
    "print('Var vector  : ---   -C-   ---   -C-   ---   ---   ---   -C-   ---   -C-  label 0')\n",
    "print('Var vector  : ---   -C-   ---   ---   ---   -C-   ---   -C-   ---   -C-  label 0')\n",
    "print('Var vector  : ---   ---   ---   -C-   ---   -C-   ---   -C-   ---   -C-  label 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the dataset\n",
    "def generate_dataset(num_items):\n",
    "    train_x = np.empty((0,20))\n",
    "    train_y = np.empty((0,1))\n",
    "    lowerB = 0.99\n",
    "    upperB = 1.01\n",
    "    lowerR = 1.2  # modify individual element of variant vector\n",
    "    upperR = 1.5  # in range [1.2, 1.5]\n",
    "\n",
    "    for i in range(0,num_items):\n",
    "        #print('*** i = ',i)\n",
    "        #Ref vector\n",
    "        ref_vector1 = np.array(np.random.uniform(low=0.01, high=0.6, size=10))\n",
    "        # Initial variant is obtained from deepcopy\n",
    "        k_adjust = random.uniform(lowerB,upperB)\n",
    "\n",
    "        var_vector1 = copy.deepcopy(ref_vector1)*k_adjust\n",
    "\n",
    "        index = (i % 40)\n",
    "\n",
    "\n",
    "        if (index == 0): \n",
    "            pos=[0]\n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 1): \n",
    "            pos=[2]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 2): \n",
    "            pos=[4]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 3): \n",
    "            pos=[6]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 4): \n",
    "            pos=[8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 5): \n",
    "            pos=[0, 2]\n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 6): \n",
    "            pos=[2, 6]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 7): \n",
    "            pos=[4, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 8): \n",
    "            pos=[0, 6]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 9): \n",
    "            pos=[2, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "\n",
    "        if (index == 10): \n",
    "            pos=[0, 4, 8]\n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 11): \n",
    "            pos=[2, 4, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 12): \n",
    "            pos=[2, 4, 6]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 13): \n",
    "            pos=[2, 6, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 14): \n",
    "            pos=[0, 4, 6]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 15): \n",
    "            pos=[0, 2, 4, 6]\n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 16): \n",
    "            pos=[0, 2, 4, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 17): \n",
    "            pos=[0, 2, 6, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 18): \n",
    "            pos=[0, 4, 6, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "        if (index == 19): \n",
    "            pos=[0, 2, 4, 6, 8]  \n",
    "            zzz_y = np.array([1])\n",
    "\n",
    "\n",
    "        if (index == 20): \n",
    "            pos=[1]\n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 21): \n",
    "            pos=[3]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 22): \n",
    "            pos=[5]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 23): \n",
    "            pos=[7]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 24): \n",
    "            pos=[9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 25): \n",
    "            pos=[1, 3]\n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 26): \n",
    "            pos=[3, 7]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 27): \n",
    "            pos=[5, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 28): \n",
    "            pos=[1, 7]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 29): \n",
    "            pos=[3, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "\n",
    "\n",
    "        if (index == 30): \n",
    "            pos=[1, 5, 9]\n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 31): \n",
    "            pos=[3, 5, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 32): \n",
    "            pos=[3, 5, 7]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 33): \n",
    "            pos=[3, 7, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 34): \n",
    "            pos=[1, 5, 7]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 35): \n",
    "            pos=[1, 3, 5, 7]\n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 36): \n",
    "            pos=[1, 3, 5, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 37): \n",
    "            pos=[1, 3, 7, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 38): \n",
    "            pos=[1, 5, 7, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "        if (index == 39): \n",
    "            pos=[1, 3, 5, 7, 9]  \n",
    "            zzz_y = np.array([0])\n",
    "\n",
    "\n",
    "\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        for j in pos:\n",
    "            var_vector1[j] = ref_vector1[j]*kk\n",
    "\n",
    "        zzz_x = np.concatenate((ref_vector1,var_vector1))   \n",
    "\n",
    "        train_x = np.append(train_x,[zzz_x],axis=0)\n",
    "        train_y = np.append(train_y,[zzz_y],axis=0)\n",
    "\n",
    "        # np.set_printoptions(precision=4)\n",
    "        # print(zzz)\n",
    "    \n",
    "    return train_x, train_y\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = generate_dataset(2000)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "test_x, test_y = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 - 1s - loss: 0.6611 - accuracy: 0.6447 - val_loss: 0.6861 - val_accuracy: 0.4733\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.3966 - accuracy: 0.8100 - val_loss: 0.6507 - val_accuracy: 0.7467\n",
      "Epoch 3/50\n",
      "27/27 - 0s - loss: 0.2694 - accuracy: 0.8818 - val_loss: 0.5974 - val_accuracy: 0.7333\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.2031 - accuracy: 0.9194 - val_loss: 0.5483 - val_accuracy: 0.8533\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.1764 - accuracy: 0.9312 - val_loss: 0.5106 - val_accuracy: 0.7200\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.1464 - accuracy: 0.9388 - val_loss: 0.4367 - val_accuracy: 0.8767\n",
      "Epoch 7/50\n",
      "27/27 - 0s - loss: 0.1337 - accuracy: 0.9506 - val_loss: 0.3890 - val_accuracy: 0.8700\n",
      "Epoch 8/50\n",
      "27/27 - 0s - loss: 0.1161 - accuracy: 0.9612 - val_loss: 0.3807 - val_accuracy: 0.8200\n",
      "Epoch 9/50\n",
      "27/27 - 0s - loss: 0.1069 - accuracy: 0.9612 - val_loss: 0.3899 - val_accuracy: 0.7433\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.0896 - accuracy: 0.9671 - val_loss: 0.2443 - val_accuracy: 0.9467\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.2361 - val_accuracy: 0.9200\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.0792 - accuracy: 0.9676 - val_loss: 0.2829 - val_accuracy: 0.8467\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.0792 - accuracy: 0.9729 - val_loss: 0.1393 - val_accuracy: 0.9833\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.0755 - accuracy: 0.9671 - val_loss: 0.1172 - val_accuracy: 0.9800\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.0819 - accuracy: 0.9729 - val_loss: 0.1286 - val_accuracy: 0.9600\n",
      "Epoch 16/50\n",
      "27/27 - 0s - loss: 0.0949 - accuracy: 0.9600 - val_loss: 0.1280 - val_accuracy: 0.9533\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.0616 - accuracy: 0.9765 - val_loss: 0.0781 - val_accuracy: 0.9867\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.0732 - accuracy: 0.9671 - val_loss: 0.0708 - val_accuracy: 0.9867\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.0935 - accuracy: 0.9624 - val_loss: 0.0970 - val_accuracy: 0.9633\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.0728 - accuracy: 0.9747 - val_loss: 0.0566 - val_accuracy: 0.9867\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.0531 - accuracy: 0.9753 - val_loss: 0.0637 - val_accuracy: 0.9767\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.0569 - accuracy: 0.9782 - val_loss: 0.0615 - val_accuracy: 0.9800\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.0670 - accuracy: 0.9753 - val_loss: 0.0682 - val_accuracy: 0.9767\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.0687 - accuracy: 0.9724 - val_loss: 0.0602 - val_accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.0583 - accuracy: 0.9759 - val_loss: 0.1322 - val_accuracy: 0.9467\n",
      "Epoch 26/50\n",
      "27/27 - 0s - loss: 0.0642 - accuracy: 0.9735 - val_loss: 0.1877 - val_accuracy: 0.9233\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.0627 - accuracy: 0.9729 - val_loss: 0.0508 - val_accuracy: 0.9733\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.0722 - accuracy: 0.9718 - val_loss: 0.0731 - val_accuracy: 0.9700\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.0545 - accuracy: 0.9806 - val_loss: 0.0504 - val_accuracy: 0.9800\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.0457 - accuracy: 0.9835 - val_loss: 0.0633 - val_accuracy: 0.9733\n",
      "Epoch 31/50\n",
      "27/27 - 0s - loss: 0.0530 - accuracy: 0.9812 - val_loss: 0.0516 - val_accuracy: 0.9833\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.0525 - accuracy: 0.9782 - val_loss: 0.0661 - val_accuracy: 0.9767\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.0868 - accuracy: 0.9671 - val_loss: 0.0372 - val_accuracy: 0.9833\n",
      "Epoch 34/50\n",
      "27/27 - 0s - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.0963 - val_accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "27/27 - 0s - loss: 0.0533 - accuracy: 0.9812 - val_loss: 0.0545 - val_accuracy: 0.9767\n",
      "Epoch 36/50\n",
      "27/27 - 0s - loss: 0.0535 - accuracy: 0.9806 - val_loss: 0.0283 - val_accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.0369 - accuracy: 0.9859 - val_loss: 0.1638 - val_accuracy: 0.9367\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.0398 - accuracy: 0.9847 - val_loss: 0.0452 - val_accuracy: 0.9867\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.0462 - accuracy: 0.9818 - val_loss: 0.0837 - val_accuracy: 0.9633\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.0621 - accuracy: 0.9776 - val_loss: 0.0396 - val_accuracy: 0.9867\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.0702 - accuracy: 0.9776 - val_loss: 0.0411 - val_accuracy: 0.9833\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.0536 - accuracy: 0.9782 - val_loss: 0.0425 - val_accuracy: 0.9867\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.0555 - accuracy: 0.9800 - val_loss: 0.0452 - val_accuracy: 0.9867\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.0665 - accuracy: 0.9753 - val_loss: 0.1294 - val_accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.0529 - accuracy: 0.9812 - val_loss: 0.0330 - val_accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.1682 - val_accuracy: 0.9400\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.0440 - accuracy: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.0705 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.0544 - accuracy: 0.9771 - val_loss: 0.0932 - val_accuracy: 0.9633\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.0503 - accuracy: 0.9776 - val_loss: 0.0472 - val_accuracy: 0.9833\n",
      "Execution time:  4.973579168319702\n",
      "63/63 - 0s - loss: 0.0438 - accuracy: 0.9830\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = ANN_model.fit(train_x, train_y, epochs=50, batch_size=64,validation_split=0.15,verbose = 2)\n",
    "\n",
    "end_time = time.time()\n",
    "exe_time = end_time - start_time\n",
    "print(\"Execution time: \", exe_time)\n",
    "\n",
    "scores = ANN_model.evaluate(test_x,test_y,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max and min \n",
      "0.9999995\n",
      "1.3749329e-08\n",
      "(2000, 20)\n",
      "(2000, 1)\n",
      "(2000, 1)\n",
      "** CHECK Average BCE Loss for multiple samples: [0.0438]\n",
      "Accuracy Score: 0.983\n",
      "error0to1 =  7 ; label is 0\n",
      "error1to0 =  27 ; label is 1\n",
      "total error =  34 percentError =  1.7\n",
      "4000 test cases: 2000 label 0; 2000 label 1\n"
     ]
    }
   ],
   "source": [
    "# To get the results of the ANN using test dataset\n",
    "y_pred = ANN_model.predict(test_x)\n",
    "\n",
    "print('  max and min ')\n",
    "print(np.max(y_pred))\n",
    "print(np.min(y_pred))\n",
    "\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "total_loss = binary_cross_entropy_check(test_y, y_pred)\n",
    "print(f\"** CHECK Average BCE Loss for multiple samples: {total_loss}\")\n",
    "\n",
    "# To check on accuracy\n",
    "# first, convert the elements in y_pred so that negative becones epsilon, largest is 1 - epsilon\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "N=len(test_y)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(test_y,y_pred_binary)\n",
    "print(\"Accuracy Score:\",accuracy)\n",
    "\n",
    "#Count error cases:\n",
    "#\n",
    "test_y_binary = test_y\n",
    "error0to1 = 0  # test_y is 0\n",
    "error1to0 = 0  # test_y is 1\n",
    "for i in range(N):\n",
    "    if (test_y_binary[i] == 0 and y_pred_binary[i] == 1):\n",
    "        error0to1 += 1\n",
    "    if (test_y_binary[i] == 1 and y_pred_binary[i] == 0):\n",
    "        error1to0 += 1\n",
    "        \n",
    "print('error0to1 = ',error0to1, '; label is 0')\n",
    "print('error1to0 = ',error1to0, '; label is 1')\n",
    "print('total error = ',error0to1+error1to0,'percentError = ', 100*(error0to1+error1to0)/N)\n",
    "print('2000 test cases: 1000 label 0; 1000 label 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x.shape  (2000, 20)\n",
      "test_y.shape  (2000, 1)\n",
      "(2000, 1)\n",
      "Compare between test_y and y_pred_binary\n",
      "[2, 1, 8, 5, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('test_x.shape ', test_x.shape)\n",
    "print('test_y.shape ',test_y.shape)\n",
    "print(y_pred_binary.shape)\n",
    "\n",
    "print('Compare between test_y and y_pred_binary')\n",
    "\n",
    "errorcase=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0,2000):\n",
    "    index = (i % 40)\n",
    "    if (index == 0 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 1 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 2 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 3 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 4 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 5 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 6 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 7 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 8 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 9 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 10 and test_y[i] != y_pred_binary[i] ): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 11 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 12 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 13 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 14 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 15 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 16 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 17 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 18 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 19 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 20 and test_y[i] != y_pred_binary[i] ): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 21 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 22 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 23 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 24 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 25 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 26 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 27 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 28 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 29 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 30 and test_y[i] != y_pred_binary[i] ): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 31 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 32 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 33 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 34 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 35 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 36 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 37 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 38 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 39 and test_y[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1       \n",
    "\n",
    "print(errorcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Sum of errors =  34\n"
     ]
    }
   ],
   "source": [
    "print(len(errorcase))\n",
    "print('Sum of errors = ' , np.sum(errorcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n",
      "(2000, 1)\n",
      "(2000, 1)\n",
      "** CHECK Average BCE Loss for multiple samples: [0.0201]\n",
      "Accuracy Score: 0.9935\n",
      "error0to1 =  3 ; label is 0\n",
      "error1to0 =  10 ; label is 1\n",
      "total error =  13 percentError =  0.65\n",
      "train cases:  2000\n"
     ]
    }
   ],
   "source": [
    "# To get the results of the ANN using train dataset\n",
    "y_pred = ANN_model.predict(train_x)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "total_loss = binary_cross_entropy_check(train_y, y_pred)\n",
    "print(f\"** CHECK Average BCE Loss for multiple samples: {total_loss}\")\n",
    "\n",
    "# To check on accuracy\n",
    "# first, convert the elements in y_pred so that negative becones epsilon, largest is 1 - epsilon\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "\n",
    "N = len(train_y)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(train_y,y_pred_binary)\n",
    "print(\"Accuracy Score:\",accuracy)\n",
    "\n",
    "#Count error cases:\n",
    "#\n",
    "train_y_binary = train_y\n",
    "error0to1 = 0  # test_y is 0\n",
    "error1to0 = 0  # test_y is 1\n",
    "for i in range(N):\n",
    "    if (train_y_binary[i] == 0 and y_pred_binary[i] == 1):\n",
    "        error0to1 += 1\n",
    "    if (train_y_binary[i] == 1 and y_pred_binary[i] == 0):\n",
    "        error1to0 += 1\n",
    "        \n",
    "print('error0to1 = ',error0to1, '; label is 0')\n",
    "print('error1to0 = ',error1to0, '; label is 1')\n",
    "print('total error = ',error0to1+error1to0,'percentError = ', 100*(error0to1+error1to0)/N)\n",
    "print('train cases: ', len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3039 0.3006 0.3049 ... 0.3006 0.3049 0.4289]\n",
      " [0.3045 0.3033 0.3086 ... 0.3599 0.3086 0.3018]\n",
      " [0.3049 0.3029 0.3019 ... 0.3978 0.3019 0.4091]\n",
      " ...\n",
      " [0.3108 0.3029 0.2993 ... 0.3029 0.2993 0.3026]\n",
      " [0.3005 0.3072 0.3018 ... 0.3072 0.4452 0.3074]\n",
      " [0.3052 0.3038 0.3063 ... 0.3038 0.3062 0.2989]]\n"
     ]
    }
   ],
   "source": [
    "# DELETE below\n",
    "# Part 2 of investigation\n",
    "# \n",
    "#\n",
    "DBset = np.empty((0,8))\n",
    "\n",
    "for i in range(0,2000):\n",
    "    #Ref vector\n",
    "    aa=np.mean(train_x[i,0:2000])\n",
    "    bb=np.mean(train_x[i,2000:4000])\n",
    "    cc=np.mean(train_x[i,4000:6000])\n",
    "    dd=np.mean(train_x[i,6000:8000])\n",
    "    #Variant vector\n",
    "    ee = np.mean(train_x[i,8192:10192])\n",
    "    ff = np.mean(train_x[i,10192:12192])\n",
    "    gg = np.mean(train_x[i,12192:14192])\n",
    "    hh = np.mean(train_x[i,14192:16192])\n",
    "    \n",
    "    index = (i % 8)\n",
    "    # index 0,1,2,3 are labe 1; index 4,5,6,7 are labe 0; \n",
    "    lowerR = 1.1\n",
    "    upperR = 1.45\n",
    "    \n",
    "    if (index == 0): \n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh*kk])\n",
    "    if (index == 1):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh])\n",
    "    if (index == 2):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh*kk])\n",
    "    if (index == 3):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff*kk, gg*kk, hh*kk])   \n",
    "        \n",
    "    if (index == 4):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg*kk, hh])\n",
    "    if (index == 5):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg, hh])\n",
    "    if (index == 6):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg*kk, hh])\n",
    "    if (index == 7):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh])  \n",
    "    \n",
    "    DBset = np.append(DBset,[zzz],axis=0)\n",
    "    # np.set_printoptions(precision=4)\n",
    "    # print(zzz)\n",
    "    \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test set of 2000\n",
    "\n",
    "DBset_test = np.empty((0,8))\n",
    "\n",
    "for i in range(0,2000):\n",
    "    #Ref vector\n",
    "    aa=np.mean(test_x[i,0:2000])\n",
    "    bb=np.mean(test_x[i,2000:4000])\n",
    "    cc=np.mean(test_x[i,4000:6000])\n",
    "    dd=np.mean(test_x[i,6000:8000])\n",
    "    #Variant vector\n",
    "    ee = np.mean(test_x[i,8192:10192])\n",
    "    ff = np.mean(test_x[i,10192:12192])\n",
    "    gg = np.mean(test_x[i,12192:14192])\n",
    "    hh = np.mean(test_x[i,14192:16192])\n",
    "    \n",
    "    index = (i % 8)\n",
    "    # index 0,1,2,3 are labe 1; index 4,5,6,7 are labe 0; \n",
    "    lowerR = 1.1\n",
    "    upperR = 1.45\n",
    "    \n",
    "    if (index == 0): \n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh*kk])\n",
    "    if (index == 1):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh])\n",
    "    if (index == 2):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh*kk])\n",
    "    if (index == 3):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff*kk, gg*kk, hh*kk])   \n",
    "        \n",
    "    if (index == 4):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg*kk, hh])\n",
    "    if (index == 5):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg, hh])\n",
    "    if (index == 6):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg*kk, hh])\n",
    "    if (index == 7):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh])  \n",
    "    \n",
    "    DBset_test = np.append(DBset_test,[zzz],axis=0)\n",
    "    # np.set_printoptions(precision=4)\n",
    "    # print(zzz)\n",
    "    \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run\n",
    "# debug\n",
    "#\n",
    "DBset_test = np.empty((0,8))\n",
    "\n",
    "for i in range(0,2000):\n",
    "    #Ref vector\n",
    "    aa=np.mean(test_x[i,0:2000])\n",
    "    bb=np.mean(test_x[i,2000:4000])\n",
    "    cc=np.mean(test_x[i,4000:6000])\n",
    "    dd=np.mean(test_x[i,6000:8000])\n",
    "    #Variant vector\n",
    "    ee = np.mean(test_x[i,8192:10192])\n",
    "    ff = np.mean(test_x[i,10192:12192])\n",
    "    gg = np.mean(test_x[i,12192:14192])\n",
    "    hh = np.mean(test_x[i,14192:16192])\n",
    "    \n",
    "    index = (i % 8)\n",
    "    # index 0,1,2,3 are labe 1; index 4,5,6,7 are labe 0; \n",
    "    lowerR = 1.1\n",
    "    upperR = 1.45\n",
    "    \n",
    "    if (index == 0): \n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh*kk])\n",
    "    if (index == 1):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh])\n",
    "    if (index == 2):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff*kk, gg, hh*kk])\n",
    "    if (index == 3):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff*kk, gg*kk, hh*kk])   \n",
    "        \n",
    "    if (index == 4):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg*kk, hh])\n",
    "    if (index == 5):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg, hh])\n",
    "    if (index == 6):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee*kk, ff, gg*kk, hh])\n",
    "    if (index == 7):\n",
    "        kk = random.uniform(lowerR,upperR)\n",
    "        zzz = np.array([aa, bb, cc, dd, ee, ff, gg, hh])  \n",
    "    \n",
    "    DBset_test = np.append(DBset_test,[zzz],axis=0)\n",
    "    # np.set_printoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n",
      "(2000,)\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    print(DBset.shape)\n",
    "    DBy = train_y[0:2000]\n",
    "    print(DBy.shape)\n",
    "    \n",
    "    print(DBy[0:16])\n",
    "    \n",
    "    print(DBset_test.shape)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/gpang/iCloudDrive/Naja/20250628-Evo2/code\\trainX_vectors3.csv\n",
      "Finished Export of Training cases \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DIR = \"C:/Users/gpang/iCloudDrive/Naja/20250628-Evo2/code\"\n",
    "out_path = os.path.join(DIR, \"trainX_vectors3.csv\")\n",
    "print(out_path)\n",
    "# DB_train.tofile(out_path,sep=',',fmt='%.5f')\n",
    "np.savetxt(out_path,DBset,delimiter=',',fmt='%.5f')\n",
    "print(\"Finished Export of Training cases \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/gpang/iCloudDrive/Naja/20250628-Evo2/code\\trainY_vectors3.csv\n",
      "Finished Export of Testing cases \n"
     ]
    }
   ],
   "source": [
    "out_path = os.path.join(DIR, \"trainY_vectors3.csv\")\n",
    "print(out_path)\n",
    "# DB_test.tofile(out_path,sep=',',fmt='#.5f')\n",
    "np.savetxt(out_path,DBy,delimiter=',',fmt='%.5f')\n",
    "print(\"Finished Export of Testing cases \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/gpang/iCloudDrive/Naja/20250628-Evo2/code\\testX_vectors3.csv\n",
      "Finished Export of Training cases \n"
     ]
    }
   ],
   "source": [
    "out_path = os.path.join(DIR, \"testX_vectors3.csv\")\n",
    "print(out_path)\n",
    "# DB_train.tofile(out_path,sep=',',fmt='%.5f')\n",
    "np.savetxt(out_path,DBset_test,delimiter=',',fmt='%.5f')\n",
    "print(\"Finished Export of Training cases \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 721\n",
      "Trainable params: 641\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim = 8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid')) # Output layer for binary classification\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "ANN_model = baseline_model3()\n",
    "\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25/25 - 1s - loss: 0.8202 - accuracy: 0.4313 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 2/40\n",
      "25/25 - 0s - loss: 0.5825 - accuracy: 0.7013 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 3/40\n",
      "25/25 - 0s - loss: 0.4539 - accuracy: 0.8669 - val_loss: 0.6780 - val_accuracy: 0.5000\n",
      "Epoch 4/40\n",
      "25/25 - 0s - loss: 0.3591 - accuracy: 0.9306 - val_loss: 0.6705 - val_accuracy: 0.5000\n",
      "Epoch 5/40\n",
      "25/25 - 0s - loss: 0.2948 - accuracy: 0.9444 - val_loss: 0.6604 - val_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "25/25 - 0s - loss: 0.2442 - accuracy: 0.9494 - val_loss: 0.6488 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "25/25 - 0s - loss: 0.1802 - accuracy: 0.9731 - val_loss: 0.6314 - val_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "25/25 - 0s - loss: 0.1544 - accuracy: 0.9825 - val_loss: 0.6261 - val_accuracy: 0.5000\n",
      "Epoch 9/40\n",
      "25/25 - 0s - loss: 0.1425 - accuracy: 0.9750 - val_loss: 0.6233 - val_accuracy: 0.5000\n",
      "Epoch 10/40\n",
      "25/25 - 0s - loss: 0.1214 - accuracy: 0.9825 - val_loss: 0.6233 - val_accuracy: 0.5000\n",
      "Epoch 11/40\n",
      "25/25 - 0s - loss: 0.1039 - accuracy: 0.9869 - val_loss: 0.6390 - val_accuracy: 0.5000\n",
      "Epoch 12/40\n",
      "25/25 - 0s - loss: 0.0989 - accuracy: 0.9800 - val_loss: 0.6719 - val_accuracy: 0.5000\n",
      "Epoch 13/40\n",
      "25/25 - 0s - loss: 0.0854 - accuracy: 0.9862 - val_loss: 0.5649 - val_accuracy: 0.5050\n",
      "Epoch 14/40\n",
      "25/25 - 0s - loss: 0.0793 - accuracy: 0.9862 - val_loss: 0.5185 - val_accuracy: 0.5400\n",
      "Epoch 15/40\n",
      "25/25 - 0s - loss: 0.0654 - accuracy: 0.9931 - val_loss: 0.4571 - val_accuracy: 0.5775\n",
      "Epoch 16/40\n",
      "25/25 - 0s - loss: 0.0658 - accuracy: 0.9906 - val_loss: 0.5082 - val_accuracy: 0.5550\n",
      "Epoch 17/40\n",
      "25/25 - 0s - loss: 0.0528 - accuracy: 0.9931 - val_loss: 0.5214 - val_accuracy: 0.5525\n",
      "Epoch 18/40\n",
      "25/25 - 0s - loss: 0.0559 - accuracy: 0.9906 - val_loss: 0.3317 - val_accuracy: 0.8125\n",
      "Epoch 19/40\n",
      "25/25 - 0s - loss: 0.0498 - accuracy: 0.9919 - val_loss: 0.3458 - val_accuracy: 0.7725\n",
      "Epoch 20/40\n",
      "25/25 - 0s - loss: 0.0454 - accuracy: 0.9950 - val_loss: 0.2367 - val_accuracy: 0.9700\n",
      "Epoch 21/40\n",
      "25/25 - 0s - loss: 0.0406 - accuracy: 0.9931 - val_loss: 0.1497 - val_accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "25/25 - 0s - loss: 0.0374 - accuracy: 0.9956 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "25/25 - 0s - loss: 0.0369 - accuracy: 0.9950 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "25/25 - 0s - loss: 0.0330 - accuracy: 0.9950 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "25/25 - 0s - loss: 0.0293 - accuracy: 0.9962 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "25/25 - 0s - loss: 0.0302 - accuracy: 0.9950 - val_loss: 0.1521 - val_accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "25/25 - 0s - loss: 0.0243 - accuracy: 0.9975 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "25/25 - 0s - loss: 0.0235 - accuracy: 0.9987 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "25/25 - 0s - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "25/25 - 0s - loss: 0.0208 - accuracy: 0.9975 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "25/25 - 0s - loss: 0.0192 - accuracy: 0.9975 - val_loss: 0.3549 - val_accuracy: 0.7750\n",
      "Epoch 32/40\n",
      "25/25 - 0s - loss: 0.0154 - accuracy: 0.9981 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "25/25 - 0s - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "25/25 - 0s - loss: 0.0147 - accuracy: 0.9987 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "25/25 - 0s - loss: 0.0117 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "25/25 - 0s - loss: 0.0172 - accuracy: 0.9975 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "25/25 - 0s - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "25/25 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "25/25 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "25/25 - 0s - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.2511 - val_accuracy: 0.8500\n",
      "Execution time:  2.315142869949341\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = ANN_model.fit(DBset, DBy, epochs=40, batch_size=64,validation_split=0.2,verbose = 2)\n",
    "\n",
    "end_time = time.time()\n",
    "exe_time = end_time - start_time\n",
    "print(\"Execution time: \", exe_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref vector  : ---   ---   ---   --- \n",
      "Var index 0 : ---   ---   ---   -C-   label 1\n",
      "Var index 1 : ---   -C-   ---   ---   label 1\n",
      "Var index 2 : ---   -C-   ---   -C-   label 1\n",
      "Var index 3 : -C-   -C-   -C-   -C-   70% label 1\n",
      "Var index 4 : ---   ---   -C-   ---   label 0\n",
      "Var index 5 : -C-   ---   ---   ---   label 0\n",
      "Var index 6 : -C-   ---   -C-   ---   label 0\n",
      "Var index 7 : -C-   -C-   -C-   -C-   0.3% label 0\n",
      "(2000, 8)\n",
      "(2000,)\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[[0.2998 0.3119 0.3061 0.3032 0.2998 0.3119 0.3061 0.4311]\n",
      " [0.3094 0.3061 0.3012 0.3067 0.3094 0.374  0.3012 0.3067]\n",
      " [0.3065 0.3079 0.3024 0.3035 0.3065 0.4077 0.3024 0.4018]\n",
      " [0.3021 0.3061 0.3095 0.3106 0.3375 0.3403 0.3473 0.3523]\n",
      " [0.3054 0.3114 0.3052 0.2988 0.3054 0.3114 0.3381 0.2988]\n",
      " [0.3064 0.3077 0.3141 0.3042 0.3998 0.3077 0.3141 0.3042]\n",
      " [0.3043 0.304  0.3102 0.3022 0.4186 0.304  0.42   0.3022]\n",
      " [0.3065 0.3089 0.3051 0.3037 0.3065 0.3091 0.3052 0.3035]]\n"
     ]
    }
   ],
   "source": [
    "print('Ref vector  : ---   ---   ---   --- ')\n",
    "print('Var index 0 : ---   ---   ---   -C- ', ' label 1')\n",
    "print('Var index 1 : ---   -C-   ---   --- ', ' label 1')\n",
    "print('Var index 2 : ---   -C-   ---   -C- ', ' label 1')\n",
    "print('Var index 3 : -C-   -C-   -C-   -C- ', ' 70% label 1')\n",
    "\n",
    "print('Var index 4 : ---   ---   -C-   --- ', ' label 0')\n",
    "print('Var index 5 : -C-   ---   ---   --- ', ' label 0')\n",
    "print('Var index 6 : -C-   ---   -C-   --- ', ' label 0')\n",
    "print('Var index 7 : -C-   -C-   -C-   -C- ', ' 0.3% label 0')\n",
    "\n",
    "print(DBset_test.shape)\n",
    "print(DBy.shape)\n",
    "print(DBy[0:16])\n",
    "print(DBset_test[0:8,0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max and min \n",
      "0.9997665\n",
      "0.092390984\n",
      "(2000, 8)\n",
      "(2000,)\n",
      "(2000, 1)\n",
      "** CHECK Average BCE Loss for multiple samples: [0.2466]\n",
      "Accuracy Score: 0.865\n",
      "error0to1 =  270 ; label is 0\n",
      "error1to0 =  0 ; label is 1\n",
      "total error =  270 percentError =  13.5\n",
      "2000 test cases: 1000 label 0; 1000 label 1\n"
     ]
    }
   ],
   "source": [
    "# To get the results of the ANN using test dataset\n",
    "y_pred = ANN_model.predict(DBset_test)\n",
    "\n",
    "print('  max and min ')\n",
    "print(np.max(y_pred))\n",
    "print(np.min(y_pred))\n",
    "\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "\n",
    "print(DBset_test.shape)\n",
    "print(DBy.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "total_loss = binary_cross_entropy_check(DBy, y_pred)\n",
    "print(f\"** CHECK Average BCE Loss for multiple samples: {total_loss}\")\n",
    "\n",
    "# To check on accuracy\n",
    "# first, convert the elements in y_pred so that negative becones epsilon, largest is 1 - epsilon\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "N=len(DBy)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(DBy,y_pred_binary)\n",
    "print(\"Accuracy Score:\",accuracy)\n",
    "\n",
    "#Count error cases:\n",
    "#\n",
    "test_y_binary = DBy\n",
    "error0to1 = 0  # test_y is 0\n",
    "error1to0 = 0  # test_y is 1\n",
    "for i in range(N):\n",
    "    if (test_y_binary[i] == 0 and y_pred_binary[i] == 1):\n",
    "        error0to1 += 1\n",
    "    if (test_y_binary[i] == 1 and y_pred_binary[i] == 0):\n",
    "        error1to0 += 1\n",
    "        \n",
    "print('error0to1 = ',error0to1, '; label is 0')\n",
    "print('error1to0 = ',error1to0, '; label is 1')\n",
    "print('total error = ',error0to1+error1to0,'percentError = ', 100*(error0to1+error1to0)/N)\n",
    "print('2000 test cases: 1000 label 0; 1000 label 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n",
      "(2000,)\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "Compare between DBy and y_pred_binary\n",
      "[0, 0, 0, 0, 12, 11, 0, 247]\n"
     ]
    }
   ],
   "source": [
    "print(DBset_test.shape)\n",
    "print(DBy.shape)\n",
    "print(DBy[0:16])\n",
    "#print(y_pred_binary.shape)\n",
    "#print(y_pred_binary[0:16])\n",
    "\n",
    "print('Compare between DBy and y_pred_binary')\n",
    "\n",
    "errorcase=[0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0,2000):\n",
    "    index = (i % 8)\n",
    "    if (index == 0 and DBy[i] != y_pred_binary[i] ): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 1 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 2 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 3 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 4 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 5 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 6 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 7 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "print(errorcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check based on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max and min \n",
      "0.9997596\n",
      "0.09228331\n",
      "(2000, 8)\n",
      "(2000,)\n",
      "(2000, 1)\n",
      "** CHECK Average BCE Loss for multiple samples: [0.248]\n",
      "Accuracy Score: 0.863\n",
      "error0to1 =  274 ; label is 0\n",
      "error1to0 =  0 ; label is 1\n",
      "total error =  274 percentError =  13.7\n",
      "2000 training cases: 1000 label 0; 1000 label 1\n"
     ]
    }
   ],
   "source": [
    "# To get the results of the ANN using train dataset\n",
    "y_pred = ANN_model.predict(DBset)\n",
    "\n",
    "print('  max and min ')\n",
    "print(np.max(y_pred))\n",
    "print(np.min(y_pred))\n",
    "\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "\n",
    "print(DBset.shape)\n",
    "print(DBy.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "total_loss = binary_cross_entropy_check(DBy, y_pred)\n",
    "print(f\"** CHECK Average BCE Loss for multiple samples: {total_loss}\")\n",
    "\n",
    "# To check on accuracy\n",
    "# first, convert the elements in y_pred so that negative becones epsilon, largest is 1 - epsilon\n",
    "epsilon = 1e-15  # Small value to prevent log(0)\n",
    "y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "N=len(DBy)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(DBy,y_pred_binary)\n",
    "print(\"Accuracy Score:\",accuracy)\n",
    "\n",
    "#Count error cases:\n",
    "#\n",
    "test_y_binary = DBy\n",
    "error0to1 = 0  # test_y is 0\n",
    "error1to0 = 0  # test_y is 1\n",
    "for i in range(N):\n",
    "    if (test_y_binary[i] == 0 and y_pred_binary[i] == 1):\n",
    "        error0to1 += 1\n",
    "    if (test_y_binary[i] == 1 and y_pred_binary[i] == 0):\n",
    "        error1to0 += 1\n",
    "        \n",
    "print('error0to1 = ',error0to1, '; label is 0')\n",
    "print('error1to0 = ',error1to0, '; label is 1')\n",
    "print('total error = ',error0to1+error1to0,'percentError = ', 100*(error0to1+error1to0)/N)\n",
    "print('2000 training cases: 1000 label 0; 1000 label 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: Compare between DBy and y_pred_binary\n",
      "[0, 0, 0, 0, 20, 8, 0, 246]\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset: Compare between DBy and y_pred_binary')\n",
    "\n",
    "errorcase=[0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0,2000):\n",
    "    index = (i % 8)\n",
    "    if (index == 0 and DBy[i] != y_pred_binary[i] ): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 1 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 2 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 3 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 4 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 5 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 6 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "    if (index == 7 and DBy[i] != y_pred_binary[i]): \n",
    "        errorcase[index] = errorcase[index]+1\n",
    "print(errorcase)\n",
    "print(np.sum(errorcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO USE BELOW\n",
    "\n",
    "#Define ANOTHER ANN model\n",
    "input_dim = 16384\n",
    "ANNmodel2 = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(1500,input_dim)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# compile with cross entropy\n",
    "ANNmodel2.compile(optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = ANNmodel2.fit(x_train, y_train, epochs=30, batch_size=32,verbose = 2)\n",
    "\n",
    "end_time = time.time()\n",
    "exe_time = end_time - start_time\n",
    "print(\"Execution time: \", exe_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ANNmodel2.evaluate(test_x,test_y,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Binary Cross-Entropy Loss (function): 0.20273661557656092\n",
      "--Average BCE Loss for multiple samples: 0.20273661557656092\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "import numpy as np\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as K\n",
    "\n",
    "# Example true labels and predicted probabilities\n",
    "y_true = np.array([0, 1, 1, 0, 1])\n",
    "y_pred = np.array([0.1, 0.9, 0.8, 0.2, 0.7])\n",
    "\n",
    "# Compute Binary Cross-Entropy using NumPy\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    bce = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return bce\n",
    "\n",
    "bce_loss = binary_cross_entropy(y_true, y_pred)\n",
    "print(f\"***Binary Cross-Entropy Loss (function): {bce_loss}\")\n",
    "\n",
    "#===========================================================================\n",
    "def binary_cross_entropy_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Binary Cross-Entropy loss for multiple samples using NumPy.\n",
    "    y_true: NumPy array of actual labels (0s and 1s)\n",
    "    y_pred: NumPy array of predicted probabilities (between 0 and 1)\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15  # Small value to prevent log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip probabilities\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "total_loss = binary_cross_entropy_np(y_true, y_pred)\n",
    "print(f\"--Average BCE Loss for multiple samples: {total_loss}\")\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "# Compute Binary Cross-Entropy using Keras\n",
    "# DOES NOT WORK\n",
    "# bce_loss_keras = binary_crossentropy(K.constant(y_true), K.constant(y_pred)).numpy()\n",
    "# print(f\"Binary Cross-Entropy Loss (Keras): {bce_loss_keras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4\n",
      "-2.5\n"
     ]
    }
   ],
   "source": [
    "aaa = np.array([0, 1, 1, -2.5, 1 , 3.4])\n",
    "bbb = np.array([0.1, 0.9, 0.8, 0.2, 0.7])\n",
    "\n",
    "print(max(aaa))\n",
    "print(min(aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    DBset = np.empty((0,4))\n",
    "    DBset_tmp = np.array([1,2,3,4])\n",
    "    DBset = np.append(DBset,[DBset_tmp],axis=0)\n",
    "    print(DBset)\n",
    "    \n",
    "    DBset_tmp = np.array([5,6,7,8])\n",
    "    DBset = np.append(DBset,[DBset_tmp],axis=0)\n",
    "\n",
    "    print(DBset)\n",
    "    print('========================')\n",
    "    DBset_tmp = np.array([9,10,11,12])\n",
    "    DBset = np.append(DBset,[DBset_tmp],axis=0)\n",
    "\n",
    "    print(DBset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
